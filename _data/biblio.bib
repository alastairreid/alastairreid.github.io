@misc{reid:hatra:2020,
      title={Towards making formal methods normal: meeting developers where they are},
      author={Alastair Reid and
              Luke Church and
              Shaked Flur and
              Sarah de Haas and
              Maritza Johnson and
              Ben Laurie},
      abstract={Formal verification of software is a bit of a niche
      activity: it is only applied to the most safety-critical or
      security-critical software and it is typically only performed by
      specialized verification engineers. This paper considers whether
      it would be possible to increase adoption of formal methods by
      integrating formal methods with developers' existing practices
      and workflows.

      We do not believe that widespread adoption will follow from
      making the prevailing formal methods argument that correctness
      is more important than engineering teams realize. Instead, our
      focus is on what we would need to do to enable programmers to
      make effective use of formal verification tools and techniques.
      We do this by considering how we might make verification tooling
      that both serves developers' needs and fits into their existing
      development lifecycle. We propose a target of two orders of
      magnitude increase in adoption within a decade driven by
      ensuring a positive `weekly cost-benefit' ratio for developer
      time invested.},
      year={2020},
      month={October},
      day={30},
      note={Accepted at HATRA 2020},
      ar_shortname = "HATRA 20",
      url = "https://research.google/pubs/pub49713/",
      eprint={2010.16345},
      archivePrefix={arXiv},
      primaryClass={cs.LO}
}

@article{conf/spisa19/armstrong,
     title = {The State of Sail},
     author = {Alasdair Armstrong and
             Thomas Bauereiss and
             Brian Campbell and
             Alastair Reid and
             Kathryn E. Gray and
             Robert Norton and
             Prashanth Mundkur and
             Mark Wassell and
             Jon French and
             Christopher Pulte and
             Shaked Flur and
             Ian Stark and
             Neel Krishnaswami and
             Peter Sewell},
    abstract = {

Sail is a custom domain-specific language for ISA semantics, in which we have
developed formal models for ARMv8-A, RISC-V, and MIPS, as well as CHERI-based
capability extensions for both RISC-V and MIPS. In particular, our model of
ARMv8-A is automatically translated from ARM-internal definitions and tested
against the ARM Architecture validation suite. All the above models contain
enough system-level features to boot various operating systems, including Linux
and FreeBSD, but also various smaller microkernels and hypervisors.

In this short paper, we present the ways in which Sail enables us to bridge the
gap between our various ISA models and the myriad use cases for such models. By
using Sail, we are able to generate emulators for testing and validation,
generate theorem prover definitions across multiple major tools (Isabelle,
HOL4, and Coq), translate Sail to SMT for automatic verification, and integrate
with both operational models for relaxed-memory concurrency via our RMEM tool.

We will also present our current work to extend Sail to support axiomatic
concurrency models, in the style of Alglave and Marangetâ€™s herd7 tool, with the
intent being to explore the behaviour of concurrent litmus tests that span the
full behaviour of the architecture. As an illustrative example, one could
consider how instruction cache maintenance instructions interact with
self-modifying code in an axiomatic setting, or other interesting cases that
are not well-covered by existing tools

},
    booktitle = {SpISA 2019: Workshop on Instruction Set Architecture Specification},
    location = {Portland, Oregon, USA},
    ar_shortname = "SpISA 19",
    year = {2019},
    month = {September}
}

@phdthesis{ReidPhDThesis2019,
    author      = {Alastair Reid},
    title       = {Defining interfaces between hardware and software: Quality and performance},
    affiliation = {School of Computing Science, University of Glasgow},
    school      = {School of Computing Science, University of Glasgow},
    abstract    = {One of the most important interfaces in a computer system is the interface
        between hardware and software.  This interface is the contract between the
        hardware designer and the programmer that defines the functional behaviour of
        the hardware.  This thesis examines two critical aspects of defining the
        hardware-software interface: quality and performance.

        The first aspect is creating a high quality specification of the interface as
        conventionally defined in an instruction set architecture.  The majority of
        this thesis is concerned with creating a specification that covers the full
        scope of the interface; that is applicable to all current implementations of
        the architecture; and that can be trusted to accurately describe the behaviour
        of implementations of the architecture.  We describe the development of
        a formal specification of the two major types of Arm processors: A-class (for
        mobile devices such as phones and tablets) and M-class (for micro-controllers).
        These specifications are unparalleled in their scope, applicability and
        trustworthiness.  This thesis identifies and illustrates what we consider the
        key ingredient in achieving this goal: creating a specification that is used by
        many different user groups.  Supporting many different groups leads to improved
        quality as each group finds different problems in the specification; and, by
        providing value to each different group, it helps justify the considerable
        effort required to create a high quality specification of a major processor
        architecture.  The work described in this thesis led to a step change in Arm's
        ability to use formal verification techniques to detect errors in their
        processors; enabled extensive testing of the specification against Arm's
        official architecture conformance suite; improved the quality of Arm's
        architecture conformance suite based on measuring the architectural coverage of
        the tests; supported earlier, faster development of architecture extensions by
        enabling animation of changes as they are being made; and enabled early
        detection of problems created from architecture extensions by performing formal
        validation of the specification against semi-structured natural language
        specifications.  As far as we are aware, no other mainstream processor
        architecture has this capability.  The formal specifications are included in
        Arm's publicly released architecture reference manuals and the A-class
        specification is also released in machine-readable form.

        The second aspect is creating a high performance interface by defining the
        hardware-software interface of a software-defined radio subsystem using
        a programming language.  That is, an interface that allows software to exploit
        the potential performance of the underlying hardware.  While the
        hardware-software interface is normally defined in terms of machine code,
        peripheral control registers and memory maps, we define it using a programming
        language instead.  This higher level interface provides the opportunity for
        compilers to hide some of the low-level differences between different systems
        from the programmer: a potentially very efficient way of providing a stable,
        portable interface without having to add hardware to provide portability
        between different hardware platforms.  We describe the design and
        implementation of a set of extensions to the C programming language to support
        programming high performance, energy efficient, software defined radio systems.
        The language extensions enable the programmer to exploit the pipeline
        parallelism typically present in digital signal processing applications and to
        make efficient use of the asymmetric multiprocessor systems designed to support
        such applications.  The extensions consist primarily of annotations that can be
        checked for consistency and that support annotation inference in order to
        reduce the number of annotations required.  Reducing the number of annotations
        does not just save programmer effort, it also improves portability by reducing
        the number of annotations that need to be changed when porting an application
        from one platform to another.  This work formed part of a project that
        developed a high-performance, energy-efficient, software defined radio capable
        of implementing the physical layers of the 4G cellphone standard (LTE), 802.11a
        WiFi and Digital Video Broadcast (DVB) with a power and silicon area budget
        that was competitive with a conventional custom ASIC solution.

        The Arm architecture is the largest computer architecture by volume in the
        world.  It behooves us to ensure that the interface it describes is
        appropriately defined.
    },
    location     = {Glasgow, Scotland},
    numpages     = {161},
    ar_shortname = "PhD 19",
    month        = {March},
    year         = {2019}
}

@inproceedings{conf/popl19/armstrong,
    title = {{ISA} Semantics for {ARMv8-A}, {RISC-V}, and {CHERI-MIPS}},
    author = {
        Alasdair Armstrong and
        Thomas Bauereiss and
        Brian Campbell and
        Alastair Reid and
        Kathryn E. Gray and
        Robert M. Norton and
        Prashanth Mundkur and
        Mark Wassell and
        Jon French and
        Christopher Pulte and
        Shaked Flur and
        Ian Stark and
        Neel Krishnaswami and
        Peter Sewell
    },
    journal   = {{PACMPL}},
    volume    = 3,
    number    = {POPL},
    booktitle = {Proc. 46th ACM SIGPLAN Symposium on Principles of Programming Languages},
    pages     = {71:1--71:31},
    year      = {2019},
    month     = {January},
    day       = {13-19},
    doi       = {10.1145/3290384},
    abstract  = {Architecture specifications notionally define the fundamental
                 interface between hardware and software: the envelope of
                 allowed behaviour for processor implementations, and the basic
                 assumptions for software development and verification.  But in
                 practice, they are typically prose and pseudocode documents,
                 not rigorous or executable artifacts, leaving software and
                 verification on shaky ground.

                 In this paper, we present rigorous semantic models for the sequential behaviour
                 of large parts of the mainstream ARMv8-A, RISC-V, and MIPS architectures, and
                 the research CHERI-MIPS architecture, that are complete enough to boot
                 operating systems, variously Linux, FreeBSD, or seL4.  Our ARMv8-A models are
                 automatically translated from authoritative ARM-internal definitions, and (in
                 one variant) tested against the ARM Architecture Validation Suite.

                 We do this using a custom language for ISA semantics, Sail, with a lightweight
                 dependent type system, that supports automatic generation of emulator code in
                 C and OCaml, and automatic generation of proof-assistant definitions for
                 Isabelle, HOL4, and (currently only for MIPS) Coq.  We use the former for
                 validation, and to assess specification coverage.  To demonstrate the usability
                 of the latter, we prove (in Isabelle) correctness of a purely functional
                 characterisation of ARMv8-A address translation.  We moreover integrate the
                 RISC-V model into the RMEM tool for (user-mode) relaxed-memory concurrency
                 exploration.  We prove (on paper) the soundness of the core Sail type system.

                 We thereby take a big step towards making the architectural abstraction
                 actually well-defined, establishing foundations for verification and reasoning.
                 },
    ar_shortname = {POPL 19},
    location  = {Cascais/Lisbon, Portugal},
    numpages  = {31},
    publisher = {ACM},
    address = {New York, NY, USA}
}

@article{conf/arw18/armstrong,
    title = {Detailed Models of Instruction Set Architectures: From Pseudocode to Formal Semantics},
    authors = {Alasdair Armstrong
               and Thomas Bauereiss
               and Brian Campbell
               and Shaked Flur
               and Kathryn E. Gray
               and Prashanth Mundkur
               and Robert Norton
               and Christopher Pulte
               and Alastair Reid
               and Peter Sewell
               and Ian Stark
               and Mark Wassell},
    abstract = {Processor instruction set architectures (ISAs) are typically
                specified using a mixture of prose and pseudocode. We present
                ongoing work on expressing such specifications rigorously and
                automatically trans- lating them to interactive theorem prover
                definitions, making them amenable to mechanised proof. Our ISA
                descriptions are written in Sailâ€”a custom ISA specification
                language designed to support idioms from var- ious processor
                vendorâ€™s pseudocode, with lightweight dependent typing for
                bitvectors, targeting a variety of use cases including
                sequential and concurrent ISA semantics. From Sail we aim to
                portably generate usable theorem prover definitions for
                multiple provers, including Isabelle, HOL4, and Coq. We are
                focusing on the full ARMv8.3-A specification, CHERI-MIPS, and
                RISC-V, together with fragments of IBM POWER and x86.
                },
    booktitle = {Automated Reasoning Workshop 2018},
    location = {Cambridge, UK},
    ar_shortname = "ARW 18",
    year = {2018},
    month = {April}
}

@inproceedings{conf/oopsla/Reid17,
    title      = {Who guards the guards? Formal Validation of the ARM v8-M Architecture Specification},
    authors    = {Alastair Reid},
    affiliation = {ARM Ltd},
    abstract = {
                Software and hardware are increasingly being formally verified
                against specifications, but how can we verify the
                specifications themselves? This talk explores what it means to
                formally verify a specification. We solve three challenges: (1)
                How to create a secondary, higher-level specification that can
                be effectively reviewed by processor designers who are not
                experts in formal verification; (2) How to avoid common-mode
                failures between the specifications; and (3) How to
                automatically verify the two specifications against each other.

                One of the most important specifications for software
                verification is the processor specification since it de nes the
                behaviour of machine code and of hardware protection features
                used by operating systems. We demonstrate our approach on ARM's
                v8-M Processor Specification, which is intended to improve the
                security of Internet of Things devices. Thus, we focus on
                establishing the security guarantees the architecture is
                intended to provide. Despite the fact that the ARM v8-M
                specification had previously been extensively tested, we found
                twelve bugs (including two security bugs) that have all been
                fixed by ARM.
                },
    journal   = {{PACMPL}},
    volume    = 1,
    number    = {OOPSLA},
    pages     = {88:1--88:24},
    year      = {2017},
    month     = {October},
    day       = {22â€“27},
    doi       = {10.1145/3133912},
    ar_shortname = "OOPSLA 17",
    location  = {Vancouver, BC, Canada},
    numpages  = {24},
    publisher = {ACM},
    address   = {New York, NY, USA}
}

@article{journal/micro/sve2017,
    title     = {The ARM Scalable Vector Extension},
    authors   = {
                Nigel Stephens
                and
                Stuart Biles
                and
                Matthias Boettcher
                and
                Jacob Eapen
                and
                Mbou Eyole
                and
                Giacomo Gabrielli
                and
                Matt Horsnell
                and
                Grigorios Magklis
                and
                Alejandro Martinez
                and
                Nathanael Premillieu
                and
                Alastair Reid
                and
                Alejandro Rico
                and
                Paul Walker
                },
    affiliation = {ARM Ltd},
    abstract = {
                In this paper we describe the ARM Scalable Vector Extension
                (SVE). Several goals guided the design of the architecture. First was
                the need to extend the vector processing capability associated with
                the ARM AArch64 execution state to better address the compute
                requirements in domains such as high performance computing (HPC), data
                analytics, computer vision and machine learning. Second was the desire
                to introduce an extension that can scale across multiple
                implementations, both now and into the future, allowing CPU designers
                to choose the vector length most suitable for their power, performance
                and area targets. Finally, the architecture should avoid imposing a
                software development cost as the vector length changes and where
                possible reduce it by improving the reach of compiler
                auto-vectorization technologies.

                We believe SVE achieves these goals. It allows implementations to
                choose a vector register length between 128 and 2048 bits. It supports
                a vector length agnostic programming model which allows code to run
                and scale automatically across all vector lengths without
                recompilation. Finally, it introduces several innovative features that
                begin to overcome some of the traditional barriers to
                auto-vectorization.
                },
    journal   = {IEEE Micro},
    month     = {March},
    year      = {2017},
    volume    = {37},
    number    = {2},
    pages     = {26--39},
    doi       = {10.1109/MM.2017.35},
    ar_shortname = "IEEE Micro",
}

@inproceedings{conf/fmcad/Reid16,
    title     = {Trustworthy Specifications of {ARM} {v8-A} and {v8-M}
                 System Level Architecture},
    authors   = {Alastair Reid},
    affiliation = {ARM Ltd},
    abstract = {
                Processor specifications are of critical importance for verifying programs,
                compilers, operating systems/hypervisors, and, of course, for verifying
                microprocessors themselves.  But to be useful, the scope of these
                specifications must be sufficient for the task, the specification must be
                applicable to processors of interest and the specification must be trustworthy.

                This paper describes a 5 year project to change ARM's existing architecture
                specification process so that machine-readable, executable specifications can
                be automatically generated from the same materials used to generate ARM's
                conventional architecture documentation.  We have developed executable
                specifications of both ARM's A-class and M-class processor architectures that
                are complete enough and trustworthy enough that we have used them to formally
                verify ARM processors using bounded model checking.  In particular, our
                specifications include the semantics of the most security sensitive parts of
                the processor: the memory and register protection mechanisms and the exception
                mechanisms that trigger transitions between different modes.  Most importantly,
                we have applied a diverse set of methods including ARM's internal processor
                test suites to improve our trust in the specification using many other
                expressions of the architectural specification such as ARM's simulators,
                testsuites and processors to defend against common-mode failure.  In the
                process, we have also found bugs in all those artifacts: testing specifications
                is very much a two-way street.

                While there have been previous specifications of ARM processors, their scope
                has excluded the system architecture, their applicability has excluded newer
                processors and M-class, and their trustworthiness has not been established as
                thoroughly.

                Our focus has been on enabling the formal verification of ARM processors but,
                recognising the value of this specification for verifying software, we are
                currently preparing a public release of the machine-readable specification.
                },
    booktitle = {Proceedings of Formal Methods in Computer-Aided Design
                 ({FMCAD} 2016)},
    location  = {Mountain View, CA, USA},
    pages     = {161-168},
    month     = {October},
    year      = {2016},
    isbn      = {978-0-9835678-6-8},
    ar_shortname = "FMCAD 16",
    url       = {https://alastairreid.github.io/papers/fmcad2016-trustworthy.pdf},
}

@inproceedings{conf/cav/Reid16,
    title      = {End-to-End Verification of {ARM} Processors with {ISA-Formal}},
    booktitle  = {Proceedings of the 2016 International Conference on Computer Aided Verification (CAV'16)},
    affiliation = {ARM Ltd},
    abstract = {
                Despite 20+ years of research on processor verification, it remains hard to use
                formal verification techniques in commercial processor development.  There are
                two significant factors: scaling issues and return on investment.  The
                scaling issues include the size of modern processor specifications, the
                size/complexity of processor designs, the size of design/verification teams and
                the (non)availability of enough formal verification experts.  The return on
                investment issues include the need to start catching bugs early in development,
                the need to continue catching bugs throughout development, and the need to be
                able to reuse verification IP, tools and techniques across a wide range of
                design styles.

                This paper describes how ARM has overcome these issues in our Instruction Set
                Architecture Formal Verification framework ``ISA-Formal.'' This is an
                end-to-end framework to detect bugs in the datapath, pipeline control and
                forwarding/stall logic of processors.  A key part of making the approach scale
                is use of a mechanical translation of ARM's Architecture Reference Manuals to
                Verilog allowing the use of commercial model-checkers.  ISA-Formal has proven
                especially effective at finding micro-architecture specific bugs involving
                complex sequences of instructions.

                An essential feature of our work is that it is able to scale all the way from
                simple 3-stage microcontrollers, through superscalar in-order processors up to
                out-of-order processors.  We have applied this method to 8 different ARM
                processors spanning all stages of development up to release.  In all
                processors, this has found bugs that would have been hard for conventional
                simulation-based verification to find and ISA-Formal is now a key part of ARM's
                formal verification strategy.

                To the best of our knowledge, this is the most broadly applicable formal
                verification technique for verifying processor pipeline control in mainstream
                commercial use.
                },
    acceptance = {28},
    editor     = {S. Chaudhuri and A. Farzan},
    series     = {Lecture Notes in Computer Science},
    volume     = {9780},
    pages      = {42-58},
    publisher  = {Springer Verlag},
    month      = {July},
    year       = {2016},
    authors    = {Alastair Reid and Rick Chen and Anastasios Deligiannis and
        David Gilday and David Hoyes and Will Keen and Ashan Pathirane and
        Erin Shepherd and Peter Vrabel and Ali Zaidi},
    journal    = {CAV 2016, Part II, Lecture Notes in Computer Science},
    location   = {Toronto, Canada},
    number     = {9780},
    doi        = {10.1007/978-3-319-41540-6_3},
    ar_shortname = "CAV 16",
    isbn       = {978-3-319-41539-0},
}

@inproceedings{DBLP:conf/date/BoettcherAEGR14,
  author    = {Matthias Boettcher and
               Bashir M. Al{-}Hashimi and
               Mbou Eyole and
               Giacomo Gabrielli and
               Alastair Reid},
    affiliation = {ARM Ltd and University of Southampton},
    abstract = {
                SIMD extensions have gained widespread acceptance in modern
                microprocessors as a way to exploit data-level parallelism in
                general-purpose cores. Popular SIMD architectures (e.g., Intel
                SSE/AVX) have evolved by adding support for wider registers and
                datapaths, and advanced features like indexed memory
                accesses, per-lane predication and inter-lane instructions, at
                the cost of additional silicon area and design complexity.

                This paper evaluates the performance impact of such advanced
                features on a set of workloads considered hard to vectorize for
                traditional SIMD architectures. Their sensitivity to the most
                relevant design parameters (e.g. register/datapath width and L1
                data cache configuration) is quantified and discussed.

                We developed an ARMv7 NEON based ISA extension (ARGON),
                augmented a cycle accurate simulation framework for it, and
                derived a set of benchmarks from the Berkeley dwarfs. Our
                analyses demonstrate how ARGON can, depending on the structure
                of an algorithm, achieve speedups of 1.5x to 16x.
                },
  editor    = {Gerhard Fettweis and
               Wolfgang Nebel},
  title     = {Advanced {SIMD:} Extending the reach of contemporary {SIMD} architectures},
  acceptance = {22},
  booktitle = {Design, Automation {\&} Test in Europe Conference {\&} Exhibition
               ({DATE} 2014)},
  location  = {Dresden, Germany},
  pages     = {1-4},
  publisher = {European Design and Automation Association},
  day       = {24-28},
  month     = {March},
  year      = {2014},
  doi       = {10.7873/DATE.2014.037},
  ar_shortname = "DATE 14",
}

@inproceedings{DBLP:conf/cases/ReidFGL08,
  author    = {Alastair D. Reid and
               Kriszti{\'a}n Flautner and
               Edmund Grimley{-}Evans and
               Yuan Lin},
  title     = {SoC-C: efficient programming abstractions for heterogeneous multicore
               systems on chip},
  affiliation = {ARM Ltd and University of Michigan},
  abstract = {
                The architectures of system-on-chip (SoC) platforms found in high-end
                consumer devices are getting more and more complex as designers strive
                to deliver increasingly compute-intensive applications on
                near-constant energy budgets.  Workloads running on these platforms
                require the exploitation of heterogeneous parallelism and increasingly
                irregular memory hierarchies.  The conventional approach to
                programming such hardware is very low-level but this yields software
                which is intimately and inseparably tied to the details of the
                platform it was originally designed for, limiting the software's
                portability, and, ultimately, the architectural choices available to
                designers of future platform generations.  The key insight of this
                paper is that many of the problems experienced in mapping applications
                onto SoC platforms come not from deciding how to map a program onto
                the hardware but from the need to restructure the program and the
                number of interdependencies introduced in the process of implementing
                those decisions.  We tackle this complexity with a set of language
                extensions which allows the programmer to introduce pipeline
                parallelism into sequential programs, manage distributed memories, and
                express the desired mapping of tasks to resources.  The compiler takes
                care of the complex, error-prone details required to implement that
                mapping.  We demonstrate the effectiveness of SoC-C and its compiler
                with a ``software defined radio'' example (the PHY layer of a Digital
                Video Broadcast receiver) achieving a 3.4x speedup on 4 cores.
              },
  editor    = {Erik R. Altman},
  acceptance = {33},
  booktitle = {Proceedings of the 2008 International Conference on Compilers, Architecture,
               and Synthesis for Embedded Systems ({CASES} 2008)},
  location  = {Atlanta, GA, USA},
  pages     = {95--104},
  publisher = {{ACM}},
  day       = {19-24},
  month     = {October},
  year      = {2008},
  doi       = {10.1145/1450095.1450112},
  ar_shortname = "CASES 08",
}

@inproceedings{DBLP:conf/micro/WohLSMMCBKRWF08,
  author    = {Mark Woh and
               Yuan Lin and
               Sangwon Seo and
               Scott A. Mahlke and
               Trevor N. Mudge and
               Chaitali Chakrabarti and
               Richard Bruce and
               Danny Kershaw and
               Alastair Reid and
               Mladen Wilder and
               Kriszti{\'a}n Flautner},
  title     = {From {SODA} to scotch: The evolution of a wireless baseband processor},
  affiliation = {ARM Ltd and University of Michigan and Arizona State University},
  abstract = {
                With the multitude of existing and upcoming wireless standards, it is becoming
                increasingly difficult for hardware-only baseband processing solutions to adapt
                to the rapidly changing wireless communication landscape. Software Defined
                Radio (SDR) promises to deliver a cost effective and flexible solution by
                implementing a wide variety of wireless protocols in software. In previous
                work, a fully programmable multicore architecture, SODA, was proposed that was
                able to meet the real-time requirements of 3G wireless protocols. SODA consists
                of one ARM control processor and four wide single instruction multiple data
                (SIMD) processing elements. Each processing element consists of a scalar and
                a wide 512-bit 32-lane SIMD datapath. A commercial prototype based on the SODA
                architecture, Ardbeg (named after a brand of Scotch Whisky), has been
                developed. In this paper, we present the architectural evolution of going from
                a research design to a commercial prototype, including the goals, trade-offs,
                and final design choices.

                Ardbeg's redesign process can be grouped into the following three major areas:
                optimizing the wide SIMD datapath, providing long instruction word (LIW)
                support for SIMD operations, and adding application-specific hardware
                accelerators. Because SODA was originally designed with 180nm technology, the
                wide SIMD datapath is re-optimized in Ardbeg for 90nm technology. This includes
                re-evaluating the most efficient SIMD width, designing a wider SIMD shuffle
                network, and implementing faster SIMD arithmetic units. Ardbeg also provides
                modest LIW support by allowing two SIMD operations to issue in the same cycle.
                This LIW execution supports SDR algorithms' most common parallel SIMD execution
                patterns with minimal hardware overhead. A viable commercial SDR solution must
                be competitive with existing ASIC solutions. Therefore, algorithm-specific
                hardware is added for performance bottleneck algorithms while still maintaining
                enough flexibility to support multiple wireless protocols. The combination of
                these architectural improvements allows Ardbeg to achieve 1.5-7x speedup over
                SODA across multiple wireless algorithms while consuming less power.
              },
  acceptance = {19},
  booktitle = {41st Annual {IEEE/ACM} International Symposium on Microarchitecture
               {(MICRO-41} 2008)},
  month     = {November},
  day       = {8-12},
  location  = {Lake Como, Italy},
  pages     = {152--163},
  publisher = {{IEEE} Computer Society},
  year      = {2008},
  doi       = {10.1109/MICRO.2008.4771787},
  ar_shortname = "MICRO 08",
}

@inproceedings{DBLP:conf/sbac-pad/OzerRB07,
  author    = {Emre {\"O}zer and
               Alastair Reid and
               Stuart Biles},
  title     = {Low-cost Techniques for Reducing Branch Context Pollution in a Soft
               Realtime Embedded Multithreaded Processor},
  affiliation = {ARM Ltd},
  abstract = {
              In this paper, we propose two low-cost and novel branch history
              buffer handling schemes aiming at skewing the branch prediction
              accuracy in favor of a real-time thread for a soft real-time
              embedded multithreaded processor. The processor core accommodates
              two running threads, one with the highest priority and the other
              thread is a background thread, and both threads share the branch
              predictor. The first scheme uses a 3-bit branch history buffer in
              which the highest priority thread uses the most significant
              2 bits to change the prediction state while the background thread
              uses only the least significant 2 bits. The second scheme uses
              the shared 2-bit branch history buffer that implements integer
              updates for the highest priority thread but fractional updates
              for the background thread in order to achieve relatively higher
              prediction accuracy in the highest priority thread. The low cost
              nature of these two schemes, particularly in the second scheme,
              makes them attractive with moderate improvement in the
              performance of the highest priority thread.
              },
  booktitle = {19th Symposium on Computer Architecture and High Performance Computing
               {(SBAC-PAD} 2007)},
  day       = {24-27},
  month     = "October",
  location  = {Gramado, RS, Brazil},
  pages     = {37--44},
  publisher = {{IEEE} Computer Society},
  year      = {2007},
  doi       = {10.1109/SBAC-PAD.2007.15},
  ar_shortname = "SBAC-PAD 07",
}

@inproceedings{DBLP:conf/sips/LinMMCRF06,
  author    = {Yuan Lin and
               Scott A. Mahlke and
               Trevor N. Mudge and
               Chaitali Chakrabarti and
               Alastair Reid and
               Kriszti{\'a}n Flautner},
  title     = {Design and Implementation of Turbo Decoders for Software Defined Radio},
  affiliation = {ARM Ltd and University of Michigan and Arizona State University},
  abstract = {
              Software Defined Radio(SDR) is an emerging paradigm for wireless
              terminals, in which the physical layer of communication
              protocols is implemented in software rather than by ASICs. Many
              of the current and next generation wireless protocols include
              Turbo coding because of its superior performance. However, Turbo
              decoding is computationally intensive, and its low power
              implementations have typ- ically been in ASICs. This paper
              presents a case study of algorithm-architecture co-design of
              Turbo decoder for SDR. We present a programmable DSP architecture
              for SDR that includes a set of architectural features to
              accelerate Turbo decoder computations. We then present a parallel
              window scheduling for MAX-Log-MAP component decoder that
              matches well with the DSP architecture. Finally, we present
              a software implementation of Turbo decoder for W-CDMA on the DSP
              architecture and show that it achieves 2Mbps decoding throughput.
              },
  booktitle = {Proceedings of the {IEEE} Workshop on Signal Processing Systems
               (SiPS 2006)},
  month     = {October},
  day       = {2-4},
  location  = {Banff, Alberta, Canada},
  pages     = {22--27},
  publisher = {{IEEE}},
  year      = {2006},
  doi       = {10.1109/SIPS.2006.352549},
  ar_shortname = "SiPS 06",
}

@inproceedings{conf:SDR:LinMW2006,
    authors = {Yuan Lin and Robert Mullenix and Mark Woh and Scott Mahlke
        and Trevor Mudge Alastair Reid and KrisztiÃ¡n Flautner},
    title = {SPEX: A programming language for software defined radio},
    booktitle = {Software Defined Radio Technical Conference and Product Exposition},
    day = {13-17},
    month = {November},
    location = {Orlando, FL, USA},
    ar_shortname = "SDR 06",
    affiliation = {ARM Ltd and University of Michigan},
    abstract = {
                High-throughput, low-power Software Defined Radio(SDR)
                solutions require multi-core SIMD DSP processors to meet
                real-time performance requirements. Given the difficulty in
                programming traditional DSPs, these new multi-core signal
                processors provide even greater challenges for programmers and
                compilers. In this paper, we describe SPEX, a programming
                language which is aimed at narrowing the semantic gap between
                the description of complex SDR systems and their
                implementations. SPEX supports three different types of
                programming semantics, allowing SDR solutions to be developed
                with a divide-and-conquer approach. For DSP algorithm
                kernels, SPEX is able to support DSP arithmetics and
                first-class vector and matrix variables with sequential
                language semantics. From wireless protocol channels, it is able
                to support sequences of data-processing computations with
                dataflow language semantics. And for protocol systems, it is
                able to support real-time deadlines and concurrent executions
                with synchronous language semantics. The design choices are
                motivated by our experience implementing W-CDMA protocol on
                a reprogrammable substrate. In the paper, we also briefly
                explain SPEX's compilation strategies.
              },
    year = {2006}
}

@article{DBLP:journals/tecs/RegehrRW05,
  author    = {John Regehr and
               Alastair Reid and
               Kirk Webb},
  title     = {Eliminating stack overflow by abstract interpretation},
  affiliation = {University of Utah},
  abstract = {
              An important correctness criterion for software running on
              embedded microcontrollers is stack safety: a guarantee that the
              call stack does not overflow. Our first contribution is a method
              for statically guaranteeing stack safety of interrupt-driven
              embedded software using an approach based on context-sensitive
              dataflow analysis of object code. We have implemented a prototype
              stack analysis tool that targets software for Atmel AVR
              microcontrollers and tested it on embedded applications compiled
              from up to 30,000 lines of C. We experimentally validate the
              accuracy of the tool, which runs in under 10 sec on the largest
              programs that we tested. The second contribution of this paper is
              the development of two novel ways to reduce stack memory
              requirements of embedded software.
              },
  journal   = {{ACM} Transactions Embedded Computing Systems},
  volume    = {4},
  number    = {4},
  pages     = {751--778},
  year      = {2005},
  doi       = {10.1145/1113830.1113833},
  ar_shortname = "TECS 05",
}

@inproceedings{DBLP:conf/asplos/RegehrR04,
  author    = {John Regehr and
               Alastair Reid},
  editor    = {Shubu Mukherjee and
               Kathryn S. McKinley},
  title     = {{HOIST:} a system for automatically deriving static analyzers for
               embedded systems},
  affiliation = {University of Utah},
  abstract = {
              Embedded software must meet conflicting requirements such as be-
              ing highly reliable, running on resource-constrained platforms,
              and being developed rapidly. Static program analysis can help
              meet all of these goals. People developing analyzers for embedded
              object code face a difficult problem: writing an abstract version
              of each instruction in the target architecture(s). This is
              currently done by hand, resulting in abstract operations that are
              both buggy and imprecise. We have developed Hoist: a novel
              system that solves these problems by automatically constructing
              abstract operations using a microprocessor (or simulator) as its
              own specification. With almost no input from a human, Hoist
              generates a collection of C functions that are ready to be
              linked into an abstract interpreter. We demonstrate that Hoist
              generates abstract operations that are correct, having been
              extensively tested, sufficiently fast, and substantially more
              precise than manually written abstract operations. Hoist is
              currently limited to eight-bit machines due to costs exponential
              in the word size of the target architecture. It is essential to
              be able to analyze software running on these small processors:
              they are important and ubiquitous, with many embedded and
              safety-critical systems being based on them.
              },
  acceptance = {14},
  booktitle = {Proceedings of the 11th International Conference on Architectural
               Support for Programming Languages and Operating Systems ({ASPLOS}
               2004)},
  location  = {Boston, MA, USA},
  month     = "October",
  day       = {7-13},
  pages     = {133--143},
  publisher = {{ACM}},
  year      = {2004},
  doi       = {10.1145/1024393.1024410},
  ar_shortname = "ASPLOS 04",
}

@inproceedings{tsl-acp4is2003,
    title = {Lock inference for systems software},
    author = {John Regehr and Alastair Reid},
    affiliation = {University of Utah},
    abstract = {
                We have developed task scheduler logic (TSL) to automate
                reasoning about scheduling and concurrency in systems software.
                TSL can detect race conditions and other errors as well as
                supporting lock inference: the derivation of an appropriate
                lock implementation for each critical section in a system. Lock
                inference solves a number of problems in creating flexible,
                reliable, and efficient systems software. TSL is based on
                a notion of asymmetrical preemption relations and it exploits
                the hierarchical inheritance of scheduling properties that is
                common in systems software.
    },
    booktitle = {Proceedings of the Second AOSD Workshop on Aspects,
        Components, and Patterns for Infrastructure Software (ACP4IS)},
    ar_shortname = "ACP4IS 03",
    location = "Boston, MA, USA",
    month = "March",
    year = "2003",
    day = "17",
    year = 2003
}

@inproceedings{DBLP:conf/emsoft/RegehrRW03,
  author    = {John Regehr and
               Alastair Reid and
               Kirk Webb},
  editor    = {Rajeev Alur and
               Insup Lee},
  title     = {Eliminating Stack Overflow by Abstract Interpretation},
  affiliation = {University of Utah},
  abstract = {
              An important correctness criterion for software running on
              embedded microcontrollers is stack safety: a guarantee that the
              call stack does not overflow. We address two aspects of the
              problem of creating stack-safe embedded software that also makes
              efficient use of memory: statically bounding worst-case stack
              depth, and automatically reducing stack memory requirements. Our
              first contribution is a method for statically guaranteeing stack
              safety by performing whole-program analysis, using an approach
              based on context-sensitive abstract interpretation of machine
              code. Abstract interpretation permits our analysis to accurately
              model when interrupts are enabled and disabled, which is
              essential for accurately bounding the stack depth of typical
              embedded systems. We have implemented a stack analysis tool that
              targets Atmel AVR microcontrollers, and tested it on embedded
              applications compiled from up to 30,000 lines of C. We
              experimentally validate the accuracy of the tool, which runs in
              a few seconds on the largest programs that we tested. The second
              contribution of this paper is a novel framework for automatically
              reducing stack memory requirements. We show that goal-directed
              global function inlining can be used to reduce the stack memory
              requirements of component-based embedded software, on average, to
              40\% of the requirement of a system compiled without inlining, and
              to 68\% of the requirement of a system compiled with aggressive
              whole-program inlining that is not directed towards reducing
              stack usage.
  },
  booktitle = {Embedded Software, Third International Conference ({EMSOFT} 2003)},
  location  = {Philadelphia, PA, USA},
  month     = {October},
  day       = {13-15},
  series    = {Lecture Notes in Computer Science},
  volume    = {2855},
  pages     = {306--322},
  publisher = {Springer},
  year      = {2003},
  doi       = {10.1007/978-3-540-45212-6_20},
  ar_shortname = "EMSOFT 03",
}

@inproceedings{DBLP:conf/rtss/RegehrRWPL03,
  author    = {John Regehr and
               Alastair Reid and
               Kirk Webb and
               Michael A. Parker and
               Jay Lepreau},
  title     = {Evolving real-time systems using hierarchical scheduling and concurrency
               analysis},
  affiliation = {University of Utah},
  abstract  = {
                We have developed a new way to look at real-time and embedded
                software: as a collection of execution environments created by
                a hierarchy of schedulers. Common schedulers include those that run
                interrupts, bottom-half handlers, threads, and events. We have
                created algorithms for deriving response times, scheduling overheads,
                and blocking terms for tasks in systems containing multiple execution
                environments. We have also created task scheduler logic, a formalism
                that permits checking systems for race conditions and other errors.
                Concurrency analysis of low-level software is challenging because
                there are typically several kinds of locks, such as thread mutexes
                and disabling interrupts, and groups of cooperating tasks may need to
                acquire some, all, or none of the available types of locks to create
                correct software. Our high level goal is to create systems that are
                evolvable: they are easier to modify in response to changing
                requirements than are systems created using traditional techniques.
                We have applied our approach to two case studies in evolving software
                for networked sensor nodes.
  },

  booktitle = {Proceedings of the 24th {IEEE} Real-Time Systems Symposium ({RTSS} 2003)},
  day       = {3-5},
  month     = {December},
  location  = {Cancun, Mexico},
  pages     = {25--36},
  publisher = {{IEEE} Computer Society},
  year      = {2003},
  doi       = {10.1109/REAL.2003.1253251},
  ar_shortname = "RTSS 03",
}

@article{report:haskellffi:chakravarty2003,
  title={The Haskell 98 Foreign Function Interface 1.0: An Addendum to the Haskell 98 Report},
  ar_shortname = "Haskell FFI",
  author = {
      Manuel Chakravarty
      and Sigbjorn Finne
      and Fergus Henderson
      and Marcin Kowalczyk
      and Daan Leijen
      and Simon Marlow
      and Erik Meijer
      and Sven Panne
      and Simon Peyton Jones
      and Alastair Reid
      and Malcolm Wallace
      and Michael Weber
  },
  year = 2003,
  url="http://web.archive.org/web/20180702051235/www.cse.unsw.edu.au/~chak/haskell/ffi/"
}

@inproceedings{DBLP:conf/icse/EideRRL02,
  author    = {Eric Eide and
               Alastair Reid and
               John Regehr and
               Jay Lepreau},
  editor    = {Will Tracz and
               Michal Young and
               Jeff Magee},
  title     = {Static and dynamic structure in design patterns},
  acceptance = {15},
  affiliation = {University of Utah},
  abstract  = {
                Design patterns are a valuable mechanism for emphasizing
                structure, capturing design expertise, and facilitating restructuring of
                software systems. Patterns are typically applied in the context of an
                object-oriented language and are implemented so that the pattern
                participants correspond to object instances that are created and
                connected at run-time. This paper describes a complementary
                realization of design patterns, in which many pattern participants
                correspond to statically instantiated and connected components.Our
                approach separates the static parts of the software design from the
                dynamic parts of the system behavior. This separation makes the
                software design more amenable to analysis, thus enabling more
                effective and domain-specific detection of system design errors,
                prediction of run-time behavior, and more effective optimization. This
                technique is applicable to imperative, functional, and
                object-oriented languages: we have extended C, Scheme, and Java with
                our component model. In this paper, we illustrate our approach in the
                context of the OSKit, a collection of operating system components
                written in C.
  },

  booktitle = {Proceedings of the 24th International Conference on Software Engineering
               ({ICSE} 2002)},
  day       = {19-25},
  month     = {May},
  location  = {Orlando, Florida, {USA}},
  pages     = {208--218},
  publisher = {{ACM}},
  year      = {2002},
  doi       = {10.1145/581339.581367},
  ar_shortname = "ICSE 02",
}

@inproceedings{EEide01Aspect,
    Author = {Eric Eide and Alastair Reid and Matthew Flatt and Jay Lepreau},
    Title = {Aspect Weaving as Component Knitting: Separating Concerns with Knit},
    ar_shortname = "ASPSE 01",
    affiliation = {University of Utah},
    abstract = {
                Knit is a new component specification and linking language. It
                was initially designed for low-level systems software, which
                requires especially flexible components with especially
                well-defined interfaces. For example, threads and virtual memory
                are typically implemented by components within the system,
                instead of being supplied by some execution environment.
                Consequently, components used to construct the system must expose
                interactions with threads and memory. The component composition
                tool must then check the resulting system for correctness, and
                weave the components together to achieve reasonable performance.

                Component composition with Knit thus acts like aspect weaving: component
                interfaces determine the ``join points'' for weaving, while components (some of
                which may be automatically generated) implement aspects. Knit is not limited to
                the construction of low-level software, and to the degree that a set of
                components exposes fine-grained relationships, Knit provides the benefits
                of aspect-oriented programming within its component model.
    },
    booktitle = {Workshop on Advanced Separation of Concerns in Software Engineering},
    location = "Toronto, Ontario, Canada",
    month = "May",
    Year = {2001}
}

@inproceedings{DBLP:conf/padl/PetersonHRH01,
  author    = {John Peterson and
               Paul Hudak and
               Alastair Reid and
               Gregory D. Hager},
  editor    = {I. V. Ramakrishnan},
  title     = {FVision: {A} Declarative Language for Visual Tracking},
  affiliation = {Yale University},
  abstract  = {
          Functional programming languages are not generally associated
          with computationally intensive tasks such as computer vision. We show
          that a declarative programming language like Haskell is effective for
          describing complex visual tracking systems. We have taken an existing
          C++ library for computer vision, called XVision, and used it to build
          FVision (pronounced ``fission''), a library of Haskell types and
          functions that provides a high-level interface to the lower-level
          XVision code. Using functional abstractions, users of FVision can
          build and test new visual tracking systems rapidly and reliably. The
          use of Haskell does not degrade system performance: computations are
          dominated by low-level calculations expressed in C++ while the
          Haskell ``glue code'' has a negligible impact on performance.

          FVision is built using functional reactive programming (FRP) to
          express interaction in a purely functional manner. The resulting
          system demonstrates the viability of mixed-language programming:
          visual tracking programs continue to spend most of their time
          executing low-level image-processing code, while Haskell's advanced
          features allow us to develop and test systems quickly and with
          confidence. In this paper, we demonstrate the use of Haskell and FRP
          to express many basic abstractions of visual tracking.
  },

    booktitle = {Practical Aspects of Declarative Languages, Third International Symposium
               ({PADL} 2001)},
  location  = {Las Vegas, Nevada, USA},
  month     = {March},
  day       = {11-12},
  series    = {Lecture Notes in Computer Science},
  volume    = {1990},
  pages     = {304--321},
  publisher = {Springer},
  year      = {2001},
  doi       = {10.1007/3-540-45241-9_21},
  ar_shortname = "PADL 01",
}

@misc{hugsgraphics2001,
    author = {Alastair Reid},
    title = {The Hugs Graphics Library (Version 2.0)},
    affiliation = {Yale University},
    location  = {New Haven, CT, USA},
    ar_shortname = "GLib 01",
    year = 2001,
}

@inproceedings{DBLP:conf/osdi/ReidFSLE00,
  author    = {Alastair Reid and
               Matthew Flatt and
               Leigh Stoller and
               Jay Lepreau and
               Eric Eide},
  editor    = {Michael B. Jones and
               M. Frans Kaashoek},
  title     = {Knit: Component Composition for Systems Software},
  affiliation = {University of Utah},
  abstract  = {
                Knit is a new component definition and linking language for
                systems code. Knit helps make C code more understandable and reusable by
                third parties, helps eliminate much of the performance overhead of
                componentization, detects subtle errors in component composition that
                cannot be caught with normal component type systems, and provides
                a foundation for developing future analyses over C-based components,
                such as cross-component optimization. The language is especially designed
                for use with component kits, where standard linking tools provide
                inadequate support for component configuration. In particular, we
                developed Knit for use with the OSKit, a large collection of
                components for building low-level systems. However, Knit is
                not OSKit-specific, and we have implemented parts of the
                Click modular router in terms of Knit components to
                illustrate the expressiveness and flexibility of our
                language. This paper provides an overview of the Knit
                language and its applications.
  },

  booktitle = {4th Symposium on Operating System Design and Implementation ({OSDI} 2000)},
  location  = {San Diego, California, USA},
  month     = {October},
  day       = {23-25},
  pages     = {347--360},
  publisher = {{USENIX} Association},
  year      = {2000},
  ar_shortname = "OSDI 00",
  url       = {http://dl.acm.org/citation.cfm?id=1251253},
}

@inproceedings{DBLP:conf/icse/ReidPHH99,
  author    = {Alastair Reid and
               John Peterson and
               Gregory D. Hager and
               Paul Hudak},
  editor    = {Barry W. Boehm and
               David Garlan and
               Jeff Kramer},
  title     = {Prototyping Real-Time Vision Systems: An Experiment in {DSL} Design},
  acceptance = {19},
  affiliation = {Yale University},
  abstract  = {
          We describe the transformation of XVision, a large library of
          C++ code for real-time vision processing, into FVision (pronounced
          ``fission''), a fully-featured domain-specific language embedded
          in Haskell. The resulting prototype system substantiates the claims
          of increased modularity, effective code reuse, and rapid prototyping
          that characterize the DSL approach to system design. It also
          illustrates the need for judicious interface design: relegating
          computationally expensive tasks to XVision (pre-existing C++
          components), and leaving modular compositional tasks to
          FVision (Haskell). At the same time, our experience demonstrates how
          Haskell's advanced language features (specifically parametric
          polymorphism, lazy evaluation, higher order functions and
          automatic storage reclamation) permit a rapid DSL design that
          is itself highly modular and easily modified. Overall, the resulting
          hybrid system exceeded our expectations: visual tracking programs
          continue to spend most of their time executing low level
          image-processing code, while Haskell's advanced features allow us to
          quickly develop and test small prototype systems within a matter of
          a few days and to develop realistic applications within a few weeks.
  },

  booktitle = {Proceedings of the 1999 International Conference on Software Engineering
               ({ICSE} '99)},
  location  = {Los Angeles, CA, USA},
  month     = {May},
  day       = {16-22},
  pages     = {484--493},
  publisher = {{ACM}},
  year      = {1999},
  doi       = {10.1109/icse.1999.841038},
  ar_shortname = "ICSE 99",
}

@inproceedings{DBLP:conf/pldi/JonesRHHM99,
  author    = {Simon L. Peyton Jones and
               Alastair Reid and
               Fergus Henderson and
               C. A. R. Hoare and
               Simon Marlow},
  editor    = {Barbara G. Ryder and
               Benjamin G. Zorn},
  title     = {A Semantics for Imprecise Exceptions},
  acceptance = {20},
  affiliation = {Yale University and Microsoft Research and Cambridge University
                 and University of Melbourne},
  abstract = {
              Some modern superscalar microprocessors provide only imprecise
              exceptions. That is, they do not guarantee to report the same exception
              that would be encountered by a straightforward sequential execution
              of the program. In exchange, they offer increased performance or
              decreased area (which amount to much the same thing).

              This performance/precision tradeoff has not so far been much explored at
              the programming language level. In this paper we propose a design for
              imprecise exceptions in the lazy functional programming language Haskell.
              We discuss various simpler designs, and conclude that imprecision is
              essential if the language is still to enjoy its current rich algebra of
              transformations. We sketch a precise semantics for the language extended
              with exceptions.

              From the functional programming point of view, the paper shows how to
              extend Haskell with exceptions without crippling the language or its
              compilers. From the point of view of the wider programming language
              community, we pose the question of whether precision and performance
              can be traded off in other languages too.  },

  booktitle = {Proceedings of the 1999 {ACM} {SIGPLAN} Conference on Programming
               Language Design and Implementation (PLDI '99)},
  location  = {Atlanta, Georgia, USA},
  month     = {May},
  day       = {1-4},
  pages     = {25--36},
  publisher = {{ACM}},
  year      = {1999},
  doi       = {10.1145/301618.301637},
  ar_shortname = "PLDI 99",
}

@misc{report:haskell98report:jones1999,
  title={Haskell 98: A non-strict, purely functional language},
  ar_shortname = "Haskell Report",
  author={
      Simon Peyton Jones
      and Lennart Augustsson
      and Dave Barton
      and Brian Boutel
      and Warren Burton
      and Joseph Fasel
      and Kevin Hammond
      and Ralf Hinze
      and Paul Hudak
      and John Hughes
      and Thomas Johnsson
      and Mark Jones
      and John Launchbury
      and Erik Meijer
      and John Peterson
      and Alastair Reid
      and Colin Runciman
      and Philip Wadler
  },
  year={1999},
  url={https://www.haskell.org/definition/}
}

@misc{report:haskell98libraries:jones1999,
  title={Standard Libraries for the Haskell 98 Programming Language},
  ar_shortname = "Haskell Lib",
  author={
      Simon Peyton Jones
      and Lennart Augustsson
      and Dave Barton
      and Brian Boutel
      and Warren Burton
      and Joseph Fasel
      and Kevin Hammond
      and Ralf Hinze
      and Paul Hudak
      and John Hughes
      and Thomas Johnsson
      and Mark Jones
      and John Launchbury
      and Erik Meijer
      and John Peterson
      and Alastair Reid
      and Colin Runciman
      and Philip Wadler
  },
  year={1999},
  url={https://www.haskell.org/definition/}
}

@inproceedings{DBLP:conf/ifl/Reid98,
  author    = {Alastair Reid},
  editor    = {Kevin Hammond and
               Antony J. T. Davie and
               Chris Clack},
  title     = {Putting the Spine Back in the Spineless Tagless G-Machine: An Implementation
               of Resumable Black-Holes},
  affiliation = {Yale University},
  abstract  = {
               Interrupt handling is a tricky business in lazy functional
               languages: we have to make sure that thunks that are being evaluated can
               be halted and later restarted if and when they are required. This is
               a particular problem for implementations which use black-holing.
               Black-Holing deliberately makes it impossible to revert such thunks
               to their original state to avoid a serious space leak. Interactive
               Haskell implementations such as Hugs and hbi catch interrupts and
               avoid the problem by omitting or disabling black-holing. Batch mode
               Haskell implementations such as HBC and the Glasgow Haskell Compiler
               (GHC) avoid this problem by disabling black-holing or by providing no
               way to catch interrupts. This paper describes a modification to GHC's
               abstract machine (the Spineless Tagless G-Machine) which
               simultaneously supports both interrupts and black-holing.},
  booktitle = {Implementation of Functional Languages, 10th International Workshop
               ({IFL}'98) Selected Papers},
  location  = {London, UK},
  month     = {September},
  day       = {9-11},
  series    = {Lecture Notes in Computer Science},
  volume    = {1595},
  pages     = {186--199},
  publisher = {Springer},
  year      = {1998},
  doi       = {10.1007/3-540-48515-5_12},
  ar_shortname = "IFL 98",
}


@inproceedings{Reid98exceptions,
    author = {Alastair Reid},
    title = {Handling Exceptions in Haskell},
    ar_shortname = "Exceptions",
    affiliation = {Yale University},
    abstract = {
        Using a language without exception handling is like driving
        a car with no brakes and no seatbelt --- things work fine until
        something goes wrong. You also learn to drive rather carefully.
        This paper describes an exception handling extension to the Haskell
        lazy functional language. The implementation turned out to be very
        easy but we had problems finding a viable semantics for our system.
        The resulting semantics is a compromise between theoretical beauty
        and practical utility.
    },

    booktitle = {Yale University Research Report YALE/DCS/RR-1178},
    location  = {New Haven, CT, USA},
    month = {August},
    year = {1998}
}

@misc{Reid98haskelllibraries,
    author = {Alastair Reid and John Peterson},
    ar_shortname = "StdLib 98",
    affiliation = {Yale University},
    title = {Designing the Standard Haskell Libraries},
    year = {1998},
}

@inproceedings{greencard1997,
    author = {Simon Peyton Jones and Thomas Nordin and Alastair Reid},
    ar_shortname = "Haskell 97",
    title = {Green Card: a foreign-language interface for Haskell},
    affiliation = {Yale University and Oregon Graduate Institute},
    booktitle = {Proceedings of the Haskell Workshop},
    location  = {Amsterdam, Netherlands},
    month = {June},
    year = {1997}
}

@inproceedings{Peterson95addingrecords,
    author = {John Peterson and Alastair Reid},
    ar_shortname = "Haskell 95a",
    title = {Adding Records to Haskell},
    affiliation = {Yale University},
    booktitle = {Proceedings of the Haskell Workshop 1995,
        Yale University Research Report YALE/DCS/RR-1075},
    location  = {Portland, Oregon, USA},
    year = {1995},
    url = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf}
}

@inproceedings{Reid95haskelllibraries,
    author = {Alastair Reid and John Peterson},
    ar_shortname = "Haskell 95b",
    title = {A Proposal for the Standard Haskell Libraries},
    affiliation = {Yale University},
    booktitle = {Proceedings of the Haskell Workshop 1995,
        Yale University Research Report YALE/DCS/RR-1075},
    location  = {Portland, Oregon, USA},
    year = {1995},
    page = {69-81},
    url = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf}
}

@inproceedings{Reid94mallocpointers,
    author = {Alastair Reid},
    ar_shortname = "GFPW 94",
    title = {Malloc Pointers and Stable Pointers: Improving Haskell's Foreign Language Interface},
    affiliation = {University of Glasgow},
    booktitle = {Draft Proceedings of the Glasgow Functional Programming Workshop},
    location = {Ayr, Scotland},
    day = {12â€“14},
    month = {September},
    year = {1994}
}

@Inbook{Reid1993,
    author="Alastair Reid and Satnam Singh",
    editor="John T. O'Donnell and Kevin Hammond",
    title="Implementing Fudgets with Standard Widget Sets",
    affiliation = {University of Glasgow},
    abstract = {
        Carlsson and Hallgren describe the implementation of a set of
        "functional widgets" (Fudgets): components for programming graphical
        user interfaces under the X window system using the non-strict
        functional programming language Haskell.
        We describe an alternative implementation based on existing
        widget sets (currently Openlook and Motif).
        Our purpose is twofold: to show that the Fudgets approach can be
        applied to existing widget sets; and to discuss problems experienced
        with Fudgets during an industrial case study.
    },
    bookTitle={Proceedings of the 1993 Glasgow Workshop on Functional Programming},
    location = {Ayr, Scotland},
    day = {5-7},
    month = {July},
    year="1993",
    publisher="Springer London",
    address="London",
    pages="222--235",
    isbn="978-1-4471-3236-3",
    doi="10.1007/978-1-4471-3236-3_18",
    ar_shortname = "GFPW 93",
}

@mastersthesis{ReidThesis93,
    author = {Alastair Reid},
    title = {A Precise Semantics for Ultraloose Specifications},
    affiliation = {University of Glasgow},
    abstract = {
              All formal specifiers face the danger of overspecification:
              accidentally writing an overly restrictive specification.
              This problem is particularly acute for axiomatic specifications
              because it is so easy to write axioms that hold for some of the
              intended implementations but not for all of them (or, rather, it
              is hard not to write overly strong axioms).

              One of the best developed ways of recovering some of these implementations
              which do not literally satisfy the specification is to apply a ``behavioural
              abstraction operator'' to a specification: adding in those implementations
              which have the same ``behaviour'' as an implementation which does satisfy
              the specification.

              In two recent papers, Broy and Wirsing propose an alternative (and apparently
              simpler) approach which they call ``ultraloose specification.''  This approach
              is based on a particular style of writing axioms which avoids certain forms
              of overspecification.

              An important, unanswered question is ``How does the ultraloose approach relate
              to other solutions?'' The major achievement of this thesis is a proof that the
              ultraloose approach is semantically equivalent to the use of the ``behavioural
              abstraction operator.''  This result is rather surprising in the light of a result
              by Schoett which seems to say that such a result is impossible.
    },
    school = {Glasgow School of Computing Science},
    location = {Glasgow, Scotland},
    ar_shortname = "MSc 93",
    year = {1993}
}

@inproceedings{DBLP:conf/fp/Reid89,
  author    = {Alastair Reid},
  editor    = {Kei Davis and
               John Hughes},
  ar_shortname = "GFPW 89",
  title     = {Designing Data Structures},
  affiliation = {University of Glasgow},
  abstract  = {
               The design (as opposed to the choice and use) of data structures has
               been the subject of relatively little study in the context of formal methods.
               In this paper, we introduce our ideas on how data structures are designed.},
  booktitle = {Proceedings of the 1989 Glasgow Workshop on Functional Programming},
  day       = {21-23},
  month     = {August},
  location  = {Fraserburgh, Scotland, {UK}},
  series    = {Workshops in Computing},
  pages     = {170--181},
  publisher = {Springer},
  year      = {1989},
}

